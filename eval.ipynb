{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm as log_progress\n",
    "\n",
    "from itertools import chain\n",
    "from razdel.utils import (\n",
    "    join_path,\n",
    "    list_paths,\n",
    "    load_lines,\n",
    "    dump_lines,\n",
    "    load_xml\n",
    ")\n",
    "from razdel.eval.etl.syntag import (\n",
    "    parse_sents as parse_syntag_sents,\n",
    "    parse_tokens as parse_syntag_tokens\n",
    ")\n",
    "from razdel.eval.etl.corpora import (\n",
    "    parse_sents as parse_corpora_sents,\n",
    "    parse_tokens as parse_corpora_tokens\n",
    ")\n",
    "from razdel.eval.etl.gicrya import (\n",
    "    parse_sents as parse_gicrya_sents,\n",
    "    parse_tokens as parse_gicrya_tokens\n",
    ")\n",
    "from razdel.eval.etl.rnc import (\n",
    "    parse_sents as parse_rnc_sents,\n",
    "    parse_tokens as parse_rnc_tokens\n",
    ")\n",
    "from razdel.tests.partition import (\n",
    "    format_partitions,\n",
    "    parse_partitions\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir -p data/raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://github.com/UniversalDependencies/UD_Russian-SynTagRus/archive/master.zip -P data/raw\n",
    "# !unzip data/raw/master.zip -d data/raw\n",
    "# !rm data/raw/master.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths = list_paths(join_path('data', 'raw', 'UD_Russian-SynTagRus-master', '*.conllu'))\n",
    "# lines = chain.from_iterable(load_lines(_) for _ in paths)\n",
    "# partitions = parse_syntag_sents(lines)\n",
    "# partitions = log_progress(partitions)\n",
    "# lines = format_partitions(partitions)\n",
    "# dump_lines(lines, join_path('data', 'syntag_sents.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths = list_paths(join_path('data', 'raw', 'UD_Russian-SynTagRus-master', '*.conllu'))\n",
    "# lines = chain.from_iterable(load_lines(_) for _ in paths)\n",
    "# partitions = parse_syntag_tokens(lines)\n",
    "# partitions = log_progress(partitions)\n",
    "# lines = format_partitions(partitions)\n",
    "# dump_lines(lines, join_path('data', 'syntag_tokens.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget http://opencorpora.org/files/export/annot/annot.opcorpora.xml.bz2 -P data/raw\n",
    "# !bunzip2 -d data/raw/annot.opcorpora.xml.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stream = load_xml(join_path('data', 'raw', 'annot.opcorpora.xml'))\n",
    "# records = parse_corpora_sents(stream)\n",
    "# records = log_progress(records)\n",
    "# lines = format_partitions(partitions)\n",
    "# dump_lines(lines, join_path('data', 'corpora_sents.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stream = load_xml(join_path('data', 'raw', 'annot.opcorpora.xml'))\n",
    "# partitions = parse_corpora_tokens(stream)\n",
    "# partitions = log_progress(partitions)\n",
    "# lines = format_partitions(partitions)\n",
    "# dump_lines(lines, join_path('data', 'corpora_tokens.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gicrya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://github.com/dialogue-evaluation/morphoRuEval-2017/raw/master/GICRYA_texts.zip -P data/raw\n",
    "# !unzip data/raw/GICRYA_texts.zip -d data/raw\n",
    "# !rm data/raw/GICRYA_texts.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lines = load_lines(join_path('data', 'raw', 'gikrya_fixed.txt'))\n",
    "# partitions = parse_gicrya_sents(lines)\n",
    "# partitions = log_progress(partitions)\n",
    "# lines = format_partitions(partitions)\n",
    "# dump_lines(lines, join_path('data', 'gicrya_sents.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lines = load_lines(join_path('data', 'raw', 'gikrya_fixed.txt'))\n",
    "# partitions = parse_gicrya_tokens(lines)\n",
    "# partitions = log_progress(partitions)\n",
    "# lines = format_partitions(partitions)\n",
    "# dump_lines(lines, join_path('data', 'gicrya_tokens.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://github.com/dialogue-evaluation/morphoRuEval-2017/raw/master/RNC_texts.rar -P data/raw\n",
    "# !unrar x data/raw/RNC_texts.rar \n",
    "# !mv RNCgoldInUD_Morpho.conll data/raw\n",
    "# !rm data/raw/RNC_texts.rar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lines = load_lines(join_path('data', 'raw', 'RNCgoldInUD_Morpho.conll'))\n",
    "# partitions = parse_rnc_sents(lines)\n",
    "# partitions = log_progress(partitions)\n",
    "# lines = format_partitions(partitions)\n",
    "# dump_lines(lines, join_path('data', 'rnc_sents.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lines = load_lines(join_path('data', 'raw', 'RNCgoldInUD_Morpho.conll'))\n",
    "# partitions = parse_rnc_tokens(lines)\n",
    "# partitions = log_progress(partitions)\n",
    "# lines = format_partitions(partitions)\n",
    "# dump_lines(lines, join_path('data', 'rnc_tokens.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from razdel.utils import (\n",
    "    join_path,\n",
    "    load_lines,\n",
    ")\n",
    "from razdel.tests.partition import parse_partitions\n",
    "\n",
    "\n",
    "lines = load_lines(join_path('data', 'syntag_sents.txt'))\n",
    "syntag_sents = list(parse_partitions(lines))\n",
    "\n",
    "lines = load_lines(join_path('data', 'corpora_sents.txt'))\n",
    "corpora_sents = list(parse_partitions(lines))\n",
    "\n",
    "lines = load_lines(join_path('data', 'gicrya_sents.txt'))\n",
    "gicrya_sents = list(parse_partitions(lines))\n",
    "\n",
    "lines = load_lines(join_path('data', 'rnc_sents.txt'))\n",
    "rnc_sents = list(parse_partitions(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from razdel.eval.zoo import dot_sentenize\n",
    "\n",
    "# pip install rusenttokenize\n",
    "from razdel.eval.zoo import deepmipt_sentenize\n",
    "\n",
    "# pip install nltk\n",
    "# nltk.download('punkt')\n",
    "# wget https://raw.githubusercontent.com/mhq/train_punkt/master/russian.pickle\n",
    "#      -O ~/nltk_data/tokenizers/punkt/PY3/russian.pickle\n",
    "from razdel.eval.zoo import nltk_sentenize\n",
    "\n",
    "# pip install segtok\n",
    "from razdel.eval.zoo import segtok_sentenize\n",
    "\n",
    "from razdel import sentenize\n",
    "\n",
    "\n",
    "# Texterra\n",
    "# Можно ещё сравнивать с https://texterra.ispras.ru/products, но\n",
    "# 1. она медленно работает, как минимум затраты на http\n",
    "# 2. иногда кидает ошибку (возможно дело в английских предложениях)\n",
    "# 3. качество немного выше segtok\n",
    "\n",
    "\n",
    "# Polyglot\n",
    "# реализует http://www.unicode.org/reports/tr29/\n",
    "\n",
    "# Сорян, не смог установить. Дикие траблы с ICU\n",
    "# brew install icu4c\n",
    "# export ICU_VERSION=62.1\n",
    "# export BASE=/usr/local/Cellar/icu4c/\n",
    "# export PATH=$PATH:$BASE/$ICU_VERSION/bin\n",
    "# export PYICU_INCLUDES=$BASE/$ICU_VERSION/include\n",
    "# export PYICU_LFLAGS=-L$BASE/$ICU_VERSION/lib\n",
    "# pip install pyicu polyglot\n",
    "\n",
    "# Вроде установилось но \n",
    "# > from polyglot.text import Text\n",
    "# > Text('...')\n",
    "# Symbol not found: __ZNK6icu_6214Transliterator12getTargetSetERNS_10UnicodeSetE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from tqdm import tqdm as log_progress\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from razdel.eval.tests import (\n",
    "    generate_precision_tests,\n",
    "    generate_recall_tests,\n",
    "    correct_precision,\n",
    "    correct_recall\n",
    ")\n",
    "from razdel.eval.report import (\n",
    "    Dataset,\n",
    "    Model,\n",
    "    Metric,\n",
    "    report_tasks,\n",
    "    run_task\n",
    ")\n",
    "\n",
    "datasets = [\n",
    "    Dataset('corpora', corpora_sents),\n",
    "    Dataset('syntag', syntag_sents),\n",
    "    Dataset('gicrya', gicrya_sents),\n",
    "    Dataset('rnc', rnc_sents),\n",
    "]\n",
    "models = [\n",
    "    Model('re.split([.?!…])', dot_sentenize),\n",
    "    Model('nltk.sent_tokenize', nltk_sentenize),\n",
    "    Model('segtok.split_single', segtok_sentenize),\n",
    "    Model('deepmipt', deepmipt_sentenize),\n",
    "    Model('razdel.sentenize', sentenize),\n",
    "]\n",
    "metrics = [\n",
    "    Metric('precision', generate_precision_tests, correct_precision),\n",
    "    Metric('recall', generate_recall_tests, correct_recall)\n",
    "]\n",
    "\n",
    "\n",
    "tasks = list(report_tasks(datasets, models, metrics))\n",
    "results = Parallel(n_jobs=4)(\n",
    "    delayed(run_task)(_)\n",
    "    for _ in log_progress(tasks)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from razdel.eval.report import (\n",
    "    result_rows,\n",
    "    show_results\n",
    ")\n",
    "\n",
    "\n",
    "table = pd.DataFrame(result_rows(results))\n",
    "print(show_results(table).to_html())\n",
    "show_results(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>corpora</th>\n",
    "      <th>syntag</th>\n",
    "      <th>gicrya</th>\n",
    "      <th>rnc</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>re.split([.?!…])</th>\n",
    "      <td>8027 (5615 + 2412), 13.1s</td>\n",
    "      <td>2188 (1761 + 427), 6.1s</td>\n",
    "      <td>4096 (2413 + 1683), 8.3s</td>\n",
    "      <td>8191 (6587 + 1604), 9.4s</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>nltk.sent_tokenize</th>\n",
    "      <td>7752 (3703 + 4049), 58.1s</td>\n",
    "      <td>1907 (951 + 956), 31.6s</td>\n",
    "      <td>2212 (829 + 1383), 36.1s</td>\n",
    "      <td>11390 (6216 + 5174), 42.5s</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>segtok.split_single</th>\n",
    "      <td>8981 (2306 + 6675), 75.2s</td>\n",
    "      <td>1971 (1090 + 881), 49.5s</td>\n",
    "      <td>79135 (914 + 78221), 12.9s</td>\n",
    "      <td>86252 (1206 + 85046), 20.5s</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>deepmipt</th>\n",
    "      <td>4529 (925 + 3604), 35.3s</td>\n",
    "      <td>579 (114 + 465), 24.5s</td>\n",
    "      <td>3502 (1647 + 1855), 24.7s</td>\n",
    "      <td>7487 (5965 + 1522), 26.0s</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>razdel.sentenize</th>\n",
    "      <td>4323 (584 + 3739), 25.7s</td>\n",
    "      <td>369 (92 + 277), 18.6s</td>\n",
    "      <td>5872 (1276 + 4596), 18.1s</td>\n",
    "      <td>4903 (2007 + 2896), 21.7s</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm as log_progress\n",
    "\n",
    "from razdel.utils import (\n",
    "    join_path,\n",
    "    load_lines,\n",
    ")\n",
    "from razdel.tests.partition import parse_partitions\n",
    "\n",
    "\n",
    "lines = log_progress(load_lines(join_path('data', 'syntag_tokens.txt')))\n",
    "syntag_tokens = list(parse_partitions(lines))\n",
    "\n",
    "lines = log_progress(load_lines(join_path('data', 'corpora_tokens.txt')))\n",
    "corpora_tokens = list(parse_partitions(lines))\n",
    "\n",
    "lines = log_progress(load_lines(join_path('data', 'gicrya_tokens.txt')))\n",
    "gicrya_tokens = list(parse_partitions(lines))\n",
    "\n",
    "lines = log_progress(load_lines(join_path('data', 'rnc_tokens.txt')))\n",
    "rnc_tokens = list(parse_partitions(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from razdel.eval.zoo import (\n",
    "    re_tokenize,\n",
    "    nltk_tokenize,  # see nltk_sentenize\n",
    ")\n",
    "\n",
    "# pip install spacy\n",
    "from razdel.eval.zoo import spacy_tokenize\n",
    "\n",
    "# pip install git+https://github.com/aatimofeev/spacy_russian_tokenizer.git\n",
    "from razdel.eval.zoo import spacy_tokenize2\n",
    "\n",
    "from razdel import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from random import seed, sample\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from razdel.eval.tests import (\n",
    "    generate_precision_tests,\n",
    "    generate_recall_tests,\n",
    "    correct_precision,\n",
    "    correct_recall\n",
    ")\n",
    "from razdel.eval.report import (\n",
    "    Dataset,\n",
    "    Model,\n",
    "    Metric,\n",
    "    report_tasks,\n",
    "    run_task\n",
    ")\n",
    "\n",
    "\n",
    "def sample_(items):\n",
    "    seed(1)\n",
    "    return sample(items, 10000)\n",
    "\n",
    "\n",
    "datasets = [\n",
    "    Dataset('corpora', sample_(corpora_tokens)),\n",
    "    Dataset('syntag', sample_(syntag_tokens)),\n",
    "    Dataset('gicrya', sample_(gicrya_tokens)),\n",
    "    Dataset('rnc', sample_(rnc_tokens)),\n",
    "]\n",
    "models = [\n",
    "    Model('re.findall(\\w+|\\d+|\\p+)', re_tokenize),\n",
    "    Model('nltk.word_tokenize', nltk_tokenize),\n",
    "    Model('spacy_tokenize', spacy_tokenize),\n",
    "    Model('spacy_tokenize2', spacy_tokenize2),\n",
    "    Model('tokenize', tokenize)\n",
    "]\n",
    "metrics = [\n",
    "    Metric('precision', generate_precision_tests, correct_precision),\n",
    "    Metric('recall', generate_recall_tests, correct_recall)\n",
    "]\n",
    "\n",
    "\n",
    "tasks = list(report_tasks(datasets, models, metrics))\n",
    "results = Parallel(n_jobs=4)(\n",
    "    delayed(run_task)(_)\n",
    "    for _ in log_progress(tasks)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from razdel.eval.report import (\n",
    "    result_rows,\n",
    "    show_results\n",
    ")\n",
    "\n",
    "table = pd.DataFrame(result_rows(results))\n",
    "print(show_results(table).to_html())\n",
    "show_results(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>corpora</th>\n",
    "      <th>syntag</th>\n",
    "      <th>gicrya</th>\n",
    "      <th>rnc</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>re.findall(\\w+|\\d+|\\p+)</th>\n",
    "      <td>1863 (1857 + 6), 13.2s</td>\n",
    "      <td>1613 (1460 + 153), 13.5s</td>\n",
    "      <td>1188 (1188 + 0), 10.9s</td>\n",
    "      <td>5005 (5002 + 3), 11.0s</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>nltk.word_tokenize</th>\n",
    "      <td>1666 (120 + 1546), 136.3s</td>\n",
    "      <td>1685 (313 + 1372), 138.6s</td>\n",
    "      <td>169 (169 + 0), 101.3s</td>\n",
    "      <td>1987 (1752 + 235), 111.3s</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>spacy_tokenize</th>\n",
    "      <td>2846 (1122 + 1724), 72.0s</td>\n",
    "      <td>2068 (987 + 1081), 71.7s</td>\n",
    "      <td>905 (905 + 0), 47.6s</td>\n",
    "      <td>2706 (2706 + 0), 49.9s</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>spacy_tokenize2</th>\n",
    "      <td>2102 (378 + 1724), 85.3s</td>\n",
    "      <td>1272 (191 + 1081), 84.1s</td>\n",
    "      <td>226 (226 + 0), 60.0s</td>\n",
    "      <td>1877 (1877 + 0), 52.7s</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>tokenize</th>\n",
    "      <td>348 (270 + 78), 26.6s</td>\n",
    "      <td>460 (383 + 77), 25.9s</td>\n",
    "      <td>151 (151 + 0), 18.6s</td>\n",
    "      <td>1755 (1752 + 3), 19.4s</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
